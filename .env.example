# =================================================================
# Bedrock Chat FastAPI Configuration Example
# =================================================================
# Copy this file to .env and modify the values as needed.
# All values shown here are the defaults used by the system.

# =================================================================
# REQUIRED: AWS Configuration
# =================================================================
# Set your AWS region where Bedrock is available
AWS_REGION=us-east-1

# AWS Credentials (optional if using IAM roles or AWS CLI profile)
# AWS_ACCESS_KEY_ID=your_access_key_here
# AWS_SECRET_ACCESS_KEY=your_secret_key_here

# =================================================================
# Model Configuration
# =================================================================
# Available Bedrock models:

# Claude Models (Anthropic)
# - us.anthropic.claude-sonnet-4-5-20250929-v1:0 (Claude 4.5 Sonnet - LATEST, most advanced)
# - us.anthropic.claude-3-5-sonnet-20241022-v2:0 (Claude 3.5 Sonnet - with inference profile)
# - anthropic.claude-3-5-sonnet-20241022-v2:0 (Claude 3.5 Sonnet - recommended, most capable)
# - anthropic.claude-3-5-haiku-20241022-v1:0 (Claude 3.5 Haiku - faster, cheaper)
# - anthropic.claude-3-haiku-20240307-v1:0 (Claude 3 Haiku - legacy, cheapest)

# OpenAI GPT OSS Models
# - openai.gpt-oss-120b-1:0 (120B parameter open-source model - excellent performance)

# Other Models
# - amazon.titan-text-express-v1 (Amazon Titan - basic text generation)
# - meta.llama3-1-70b-instruct-v1:0 (Meta Llama 3.1 70B - open-source)

# Default: Claude 4.5 Sonnet (latest and most advanced)
BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0

# Temperature controls randomness (0.0 = deterministic, 1.0 = very random)
BEDROCK_TEMPERATURE=0.7

# Maximum tokens in model response (affects cost and response length)
BEDROCK_MAX_TOKENS=4096

# Top-p sampling parameter (0.0-1.0)
# PARAMETER COMPATIBILITY:
# - Claude models: Use EITHER temperature OR top_p, not both (validation error if both)
# - OpenAI GPT models: Support BOTH temperature AND top_p simultaneously
# - Other models: Check model-specific documentation
BEDROCK_TOP_P=0.9

# =================================================================
# System Prompt
# =================================================================
# Define the AI assistant's behavior and capabilities
BEDROCK_SYSTEM_PROMPT="You are a helpful AI assistant for this API. Use the available tools to provide accurate information and help users accomplish their tasks."

# =================================================================
# API Endpoints
# =================================================================
# Customize the chat endpoints
BEDROCK_CHAT_ENDPOINT=/bedrock-chat
BEDROCK_WEBSOCKET_ENDPOINT=/bedrock-chat/ws
BEDROCK_UI_ENDPOINT=/bedrock-chat/ui

# Enable/disable the built-in chat UI
BEDROCK_ENABLE_UI=true

# =================================================================
# Tool Configuration
# =================================================================
# Which API paths the AI can access (comma-separated)
# Leave empty to allow all paths except excluded ones
BEDROCK_ALLOWED_PATHS=

# Which API paths to exclude from AI access (comma-separated)
BEDROCK_EXCLUDED_PATHS=/docs,/redoc,/openapi.json,/bedrock-chat

# Maximum tool calls per conversation turn (prevents infinite loops)
BEDROCK_MAX_TOOL_CALLS=10

# Timeout for API calls in seconds
BEDROCK_TIMEOUT=30

# =================================================================
# Session Management
# =================================================================
# Maximum concurrent WebSocket sessions
BEDROCK_MAX_SESSIONS=1000

# Session timeout in seconds (1 hour = 3600)
BEDROCK_SESSION_TIMEOUT=3600

# =================================================================
# Security
# =================================================================
# Rate limiting (examples: "10/minute", "100/hour", "1000/day")
# BEDROCK_RATE_LIMIT=60/minute

# CORS origins (comma-separated, * for all)
BEDROCK_CORS_ORIGINS=*

# =================================================================
# Logging
# =================================================================
# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
BEDROCK_LOG_LEVEL=INFO

# Log all API calls for debugging (can be verbose)
BEDROCK_LOG_API_CALLS=false

# Log errors
BEDROCK_LOG_ERRORS=true

# =================================================================
# Error Handling & Reliability
# =================================================================
# Maximum retries for failed requests
BEDROCK_MAX_RETRIES=3

# Delay between retries in seconds
BEDROCK_RETRY_DELAY=1.0

# Use exponential backoff for retries
BEDROCK_EXPONENTIAL_BACKOFF=true

# Continue working even if some features fail
BEDROCK_GRACEFUL_DEGRADATION=true

# Fallback model if primary model fails
# BEDROCK_FALLBACK_MODEL=anthropic.claude-3-5-haiku-20241022-v1:0

# =================================================================
# Conversation Management
# =================================================================
# Maximum number of conversation messages to keep in history
BEDROCK_MAX_CONVERSATION_MESSAGES=50

# Conversation trimming strategy: sliding_window, truncate, smart_prune
BEDROCK_CONVERSATION_STRATEGY=smart_prune

# Whether to preserve system message during conversation trimming
BEDROCK_PRESERVE_SYSTEM_MESSAGE=true

# =================================================================
# Message Chunking
# =================================================================
# Enable automatic message chunking for large content
BEDROCK_ENABLE_MESSAGE_CHUNKING=true

# Maximum message size before chunking (in characters)
BEDROCK_MAX_MESSAGE_SIZE=100000

# Size of each chunk (in characters)
BEDROCK_CHUNK_SIZE=50000

# Message chunking strategy: simple, preserve_context, semantic
BEDROCK_CHUNKING_STRATEGY=preserve_context

# Overlap between chunks for context preservation (in characters)
BEDROCK_CHUNK_OVERLAP=5000

# =================================================================
# Advanced Tool Handling
# =================================================================
# Maximum number of recursive tool call rounds
BEDROCK_MAX_TOOL_CALL_ROUNDS=5

# =================================================================
# Environment-Specific Overrides
# =================================================================

# Development settings (faster/cheaper models for testing)
# BEDROCK_MODEL_ID=anthropic.claude-3-5-haiku-20241022-v1:0
# BEDROCK_TEMPERATURE=0.3
# BEDROCK_LOG_API_CALLS=true
# BEDROCK_LOG_LEVEL=DEBUG

# Production settings (latest models with security)
# BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0
# BEDROCK_ENABLE_UI=false
# BEDROCK_RATE_LIMIT=30/minute
# BEDROCK_LOG_API_CALLS=false
# BEDROCK_MAX_SESSIONS=500

# Testing settings (deterministic responses)
# BEDROCK_MODEL_ID=openai.gpt-oss-120b-1:0
# BEDROCK_TEMPERATURE=0.0
# BEDROCK_MAX_TOOL_CALLS=3
# BEDROCK_TIMEOUT=10